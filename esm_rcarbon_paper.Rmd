---
title: "Inferences from large sets of radiocarbon dates: software and method - Electronic Supplementary Material"
author: "E.Crema"
date: "9 April 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This document includes R scripts for generating all figures in the article _Inferences from large sets of radiocarbon dates: software and method_, as well as supplementary figures and their scripts.    

# Setup

All analyses and figures require the installation of the _rcarbon_ package version <!-- specify version here --> and the download of several supporting data. To install _rcarbon_ type the following command in the R console:

```{r,eval=FALSE}
# install.packages('devtools') ## execute the line if devtools is not installed
devtools::install_github("ahb108/rcarbon")
```

<!-- In case the package in submitted to CRAN -->
<!-- ```{r,eval=FALSE}
install.packages("rcarbon")
``` -->

Once the package is downloaded and installed, load _rcarbon_ by typing:

```{r}
library(rcarbon)
```

To reproduce the figures in the article the following data should be imported or loaded in R:

<!-- Perhaps worth creating two sections, one for the figures in the article and one for the supplementary figures -->
<!-- AB: Or we can put them all together...presumably we will just submit a zip file with the raw data and Rmd file, but no html/pdf?-->

# Main Article Figures 


## Figure 1
<!-- Not yet checked wiht the knitted version -->
```{r,fig.width=6,fig.height=7}
data(euroevol)
grimes <- euroevol[grepl("S2072", euroevol$SiteID),]
grimesc <- calibrate(x=grimes$C14Age, errors=grimes$C14SD, ids=grimes$C14ID, normalised=FALSE,verbose = FALSE)
workingstartBP <- 7500
workingendBP <- 2500
gspd0 <- spd(x=grimesc, timeRange=c(workingstartBP,workingendBP), datenormalised=TRUE,verbose = FALSE)
threedates <- grimes[grimes$LabCode %in% c("BM-1022","BM-1033","BM-1066"),]
threedatesc <- calibrate(x=threedates$C14Age, errors=threedates$C14SD, ids=threedates$C14ID, normalised=FALSE,verbose=FALSE)

## Thinned version
n <- 10
inds <- thinDates(ages=grimes$C14Age,errors=grimes$C14SD,grimes$SiteID,size=n,method="random", seed=99)
grimesthin <- grimes[inds,]
grimesthinc <- calibrate(x=grimesthin$C14Age, errors=grimesthin$C14SD, ids=grimesthin$C14ID, normalised=FALSE,verbose = FALSE)
gspdthin <- spd(x=grimesthinc, timeRange=c(workingstartBP,workingendBP), datenormalised=TRUE,verbose = FALSE)

## Binned version
bins50 <- binPrep(sites=grimes$SiteID, ages=grimes$C14Age, h=50)
bins100 <- binPrep(sites=grimes$SiteID, ages=grimes$C14Age, h=100)
bins200 <- binPrep(sites=grimes$SiteID, ages=grimes$C14Age, h=200)
gspd50 <- spd(x=grimesc, bins=bins50, timeRange=c(workingstartBP,workingendBP), datenormalised=TRUE,verbose = FALSE)
gspd100<- spd(x=grimesc, bins=bins100, timeRange=c(workingstartBP,workingendBP), datenormalised=TRUE,verbose = FALSE)
gspd200 <- spd(x=grimesc, bins=bins200, timeRange=c(workingstartBP,workingendBP), datenormalised=TRUE,verbose = FALSE)

## I think we should add a proper 'add=TRUE' option to the basic plot.CalDates so the fiddling with polygons below is not necessary, it could work only off type=simple, for instance.
# dev.new(device=pdf, width=6, height=7)
layout(matrix(c(1,1,2,3,4,5), 3, 2, byrow=TRUE), widths=c(3,3), heights=c(3,2,2))
par(mar=c(4, 4, 1, 0.5)) #c(bottom, left, top, right)
plot(gspd0, calendar="BCAD", fill.p="chocolate1")
plot(gspd0, runm=50, calendar="BCAD", add=TRUE, fill.p=NA, border="chocolate4")
plot(threedatesc[1],add=TRUE,calendar='BCAD', col='black')
plot(threedatesc[2],add=TRUE,calendar='BCAD', col='black')
plot(threedatesc[3],add=TRUE,calendar='BCAD', col='black')

legend("topleft", bty="n", col=c("chocolate1","chocolate4","black"), legend=c("raw SPD", "smoothed (50-yr running mean)", "3 example dates"), lwd=c(5,1,5), cex=0.8)
text(-5400, 0.02, "a", font=2)

par(mar=c(0.5, 3, 0.5, 0.5)) #c(bottom, left, top, right)

plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="white", spdnormalised=TRUE)
plot(gspdthin, xaxt="n", yaxt="n", runm=50, fill.p="aquamarine", spdnormalised=TRUE, add=TRUE)
plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="chocolate4", spdnormalised=TRUE, add=TRUE)
legend("topleft", bty="n", col=c("chocolate4","aquamarine"), legend=c("original SPD", paste("Thinned to ", nrow(grimesthin), " random dates", sep="")), lwd=c(1,5), cex=0.8)
text(7200, 0.00015, "b", font=2)

plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="white", spdnormalised=TRUE)
plot(gspd50, xaxt="n", yaxt="n", runm=50, fill.p="bisque3", spdnormalised=TRUE, add=TRUE)
plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="chocolate4", spdnormalised=TRUE, add=TRUE)
legend("topleft", bty="n", col=c("chocolate4","bisque3"), legend=c("original SPD", "50 year bins"), lwd=c(1,5), cex=0.8)
text(7200, 0.00015, "c", font=2)

plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="white", spdnormalised=TRUE)
plot(gspd100, xaxt="n", yaxt="n", runm=50, fill.p="bisque3", spdnormalised=TRUE, add=TRUE)
plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="chocolate4", spdnormalised=TRUE, add=TRUE)
legend("topleft", bty="n", col=c("chocolate4","bisque3"), legend=c("original SPD", "100 year bins"), lwd=c(1,5), cex=0.8)
text(7200, 0.00015, "d", font=2)

plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="white", spdnormalised=TRUE)
plot(gspd200, xaxt="n", yaxt="n", runm=50, fill.p="bisque3", spdnormalised=TRUE, add=TRUE)
plot(gspd0, xaxt="n", yaxt="n", runm=50, fill.p=NA, border="chocolate4", spdnormalised=TRUE, add=TRUE)
legend("topleft", bty="n", col=c("chocolate4","bisque3"), legend=c("original SPD", "200 year bins"), lwd=c(1,5), cex=0.8)
text(7200, 0.00015, "e", font=2)
```

## Figure 2

<!-- consider renaming the columns in the CSV for consistency? -->
<!-- consider removing undrscores from brazil sitenames in csv -->
<!-- calibration curve still needed? -->

The code below compares the summed probability distribution (SPD) of three distinct geographic regions (Southern Levant, Sahara, and Brazil) using normalised calibrated dates. 

First we calibrate the dates. For the purpose of this figure no binning will be employed, and the dates are be immediately aggregated to generate the SPDs:

```{r}
# Read Calibration Curve For Visualisation
intcal13 <- read.csv('http://www.radiocarbon.org/IntCal13%20files/intcal13.14c', encoding="UTF-8",skip=11,header=F)
colnames(intcal13) <- c("BP","CRA","Error","D14C","Sigma")

# Roberts, Neil, Jessie Woodbridge, Andrew Bevan, Alessio Palmisano, Stephen Shennan, and Eleni Asouti. “Human Responses and Non-Responses to Climatic Variations during the Last Glacial-Interglacial Transition in the Eastern Mediterranean.” Quaternary Science Reviews, Late Glacial to Early Holocene socio-ecological responses to climatic instability within the Mediterranean basin, 184 (March 15, 2018): 47–67. https://doi.org/10.1016/j.quascirev.2017.09.011.
data(emedyd) # this is available within the rcarbon package
southLevant <- subset(emedyd,Region=='1'&CRA<=17000&CRA>=8000)

#Manning, Katie, and Adrian Timpson. “The Demographic Response to Holocene Climate Change in the Sahara.” Quaternary Science Reviews 101 (October 1, 2014): 28–35. https://doi.org/10.1016/j.quascirev.2014.07.003.
sahara <- read.csv('./data/Manning_and_Timpson2014.csv',header=TRUE)
sahara <- subset(sahara,Yrs.BP<=17000&Yrs.BP>=8000)

#Bueno, Lucas, Adriana Schmidt Dias, and James Steele. “The Late Pleistocene/Early Holocene Archaeological Record in Brazil: A Geo-Referenced Database.” Quaternary International, A Late Pleistocene/early Holocene archaeological 14C database for Central and South America: palaeoenvironmental contexts and demographic interpretations, 301 (July 8, 2013): 74–93. https://doi.org/10.1016/j.quaint.2013.03.042.
brazil <- read.csv('./data/Bueno_etal_2013.csv',header=TRUE)
brazil <- subset(brazil,OccCRA<=17000&OccCRA>=8000)
```
<!-- updated version matching the current version of the manuscript as for 09042019 -->

```{r}
## Calibrate Dates
southlevant.x = calibrate(southLevant$CRA,southLevant$Error,normalised=F,verbose=F)
sahara.x = calibrate(sahara$Yrs.BP,sahara$STD,normalised=F,verbose=F)
brazil.x = calibrate(brazil$CRA,brazil$Error,normalised=F,verbose=F)

## Minimal binning to control for sites with many dates.
southlevant.bins <- binPrep(sites=southLevant$SiteName, ages=southLevant$CRA, h=50)
sahara.bins <- binPrep(sites=sahara$Sitename, ages=sahara$Yrs.BP, h=50)
brazil$SiteName <- sub("_","",brazil$SiteName) ##can we fix this in the csv?
brazil.bins <- binPrep(sites=brazil$SiteName, ages=brazil$CRA, h=50)

## Aggregate 
southlevant.spd.nnorm = spd(southlevant.x, bins=southlevant.bins, timeRange=c(16000,9000),verbose=F)
sahara.spd.nnorm = spd(sahara.x, bins=sahara.bins, timeRange=c(16000,9000),verbose=F)
brazil.spd.nnorm = spd(brazil.x, bins=brazil.bins, timeRange=c(16000,9000),verbose=F)
southlevant.spd.norm = spd(southlevant.x, bins=southlevant.bins, timeRange=c(16000,9000),verbose=F,datenormalised=T)
sahara.spd.norm = spd(sahara.x, bins=sahara.bins, timeRange=c(16000,9000),verbose=F,datenormalised=T)
brazil.spd.norm = spd(brazil.x, bins=brazil.bins, timeRange=c(16000,9000),verbose=F,datenormalised=T)
```


```{r,fig.width=12,fig.height=6}
## Plot
fmat=matrix(c(rep(1,3),rep(2,3),rep(3:5,each=2)),nrow=6,ncol=2)
layout(fmat,widths=c(0.4,0.8),heights=c(1.2,1,0.8,0.8,1,1.2))
x1 = calibrate(3523,45,normalised = F,verbose=F)
plot(x1,type='auc',cex.lab=1,cex.axis=1)

#title(paste0("auc non-normalised:",round(sum(x1$grids$`1`$PrDens),3)))
title("a",line=-2)
x2 = calibrate(4274,45,normalised = F,verbose=F)
plot(x2,type='auc',cex.lab=1,cex.axis=1)


#title(paste0("auc non-normalised:",round(sum(x2$grids$`1`$PrDens),3)))
title("b",line=-2)
par(yaxs="i")
par(xaxs="i")
par(mar=c(0,6,6,1)) # c(bottom, left, top, right)
plot(southlevant.spd.nnorm,fill.p=NA, xlim=c(14000,9000), ylim=c(0,0.25), xaxt="n",yaxt='n',cex.lab=1,cex.axis=0)
rect(x=c(9509.948,10228.445,11241.710,12690)+100,xright=c(9509.948,10228.445,11241.710,12690)-100,ybottom=rep(-100,4),ytop=rep(100,5),border=NA,col='orange')
plot(southlevant.spd.nnorm,fill.p='bisque3',ylim=c(0,0.25), xaxt="n", add=TRUE)
plot(southlevant.spd.norm,type='simple', xaxt="n",add=TRUE)
lines(intcal13[intcal13$BP<=14000 & intcal13$BP>=9000,"BP"],reScale(intcal13[intcal13$BP<=14000 & intcal13$BP>=9000,"CRA"])*par('usr')[4],col="red",lwd=2)
legend("topleft",legend=c("Unnormalised SPD","Normalised SPD", "IntCal13","Areas with spikes"),col=c('bisque3','black',"red","orange"),lwd=c(5,1,1,5))
title("c",line=-2)

par(mar=c(0,6,0,1))
plot(sahara.spd.nnorm,fill.p=NA, xlim=c(14000,9000), ylim=c(0,0.35), xaxt="n",yaxt='n',cex.lab=1)
rect(x=c(9509.948,10228.445,11241.710,12690)+100,xright=c(9509.948,10228.445,11241.710,12690)-100,ybottom=rep(-100,4),ytop=rep(100,5),border=NA,col='orange')
plot(sahara.spd.nnorm,fill.p='bisque3',ylim=c(0,0.35), xaxt="n", add=TRUE)
plot(sahara.spd.norm,type = 'simple', xaxt="n",add=TRUE)
lines(intcal13[intcal13$BP<=14000 & intcal13$BP>=9000,"BP"],reScale(intcal13[intcal13$BP<=14000 & intcal13$BP>=9000,"CRA"])*par('usr')[4],col="red",lwd=2)
title("d",line=-2)
title(ylab="Summed Probability",cex.lab=1.5,line=0.5)

par(mar=c(6,6,0,1))
plot(brazil.spd.nnorm,fill.p=NA, xlim=c(14000,9000), ylim=c(0,0.125), xaxt="n",yaxt='n',cex.lab=1,cex.axis=0)
rect(x=c(9509.948,10228.445,11241.710,12690)+100,xright=c(9509.948,10228.445,11241.710,12690)-100,ybottom=rep(-100,4),ytop=rep(100,5),border=NA,col='orange')
plot(brazil.spd.nnorm,fill.p='bisque3',ylim=c(0,0.125), xaxt="n", add=TRUE)
plot(brazil.spd.norm,type = 'simple', xaxt="n", add=TRUE)
axis(side=1, at=seq(14000,9000,-1000), labels=seq(14000,9000,-1000), las=2, cex.axis=1)
lines(intcal13[intcal13$BP<=14000 & intcal13$BP>=9000,"BP"],reScale(intcal13[intcal13$BP<=14000 & intcal13$BP>=9000,"CRA"])*par('usr')[4],col="red",lwd=2)
title("e",line=-2)
```


## Figure 3 

The `calsample` method implemented using normalised and non-normalised dates. The method fails to emulate peaks in the SPD corresponding to the steeper portions of the calibration curve. 

```{r}
southlevant.x = calibrate(southLevant$CRA,southLevant$Error,normalised=TRUE,verbose=FALSE)
southlevant.x2 = calibrate(southLevant$CRA,southLevant$Error,normalised=FALSE,verbose=FALSE)

test.cal.nn = modelTest(southlevant.x2,errors=southLevant$Error,timeRange=c(16000,9000), nsim=1000, ncores=3, method='calsample', normalised = FALSE,runm=50,verbose=FALSE)

test.cal.n = modelTest(southlevant.x,errors=southLevant$Error,timeRange=c(16000,9000), nsim=1000, ncores=3, method='calsample', normalised = TRUE,runm=50,verbose=FALSE)
```

The `uncalsample` method implemented using normalised and non-normalised dates. The method emulates the peaks in the SPD corresponding to the steeper portions of the calibration curve. 

```{r}
test.uncal.nn = modelTest(southlevant.x2,errors=southLevant$Error,timeRange=c(16000,9000), nsim=1000, ncores=3, method='uncalsample', normalised = FALSE,runm=50,verbose=FALSE)

test.uncal.n = modelTest(southlevant.x,errors=southLevant$Error,timeRange=c(16000,9000), nsim=1000, ncores=3, method='uncalsample', normalised = TRUE,runm=50,verbose=FALSE)
```


```{r,fig.width=10,fig.height=10}
par(mfrow=c(2,2))
plot(test.cal.n,lwd.obs = 1.5)
title('a')
plot(test.cal.nn,lwd.obs = 1.5)
title('b')
plot(test.uncal.n,lwd.obs = 1.5)
title('c')
plot(test.uncal.nn,lwd.obs = 1.5)
title('d')
```

## Figure 4 
```{r,fig.height=2.5,fig.width=8}
## Example with a subset of English and Welsh dates from the Euroevol dataset
data(ewdates)
data(ewowin)
x <- calibrate(x=ewdates$C14Age, errors=ewdates$C14SD, normalised=FALSE)
## Create centennial timeslices (also with site binning)
bins1 <- binPrep(sites=ewdates$SiteID, ages=ewdates$C14Age, h=50)
stkde1 <- stkde(x=x, coords=ewdates[,c("Eastings", "Northings")], win=ewowin, sbw=40000, cellres=2000, focalyears=seq(6500, 5000, -100), tbw=100, bins=bins1, backsight=200, outdir="im",amount=1)
## Plot an example of all four basic outputs for 6000 calBP
par(mar=c(0.5, 0.5, 2.5, 2))
plot(stkde1, 6000, type="all")
```


# Figure 5 

```{r,fig.height=5,fig.width=8}
library(maptools)
data(ewdates)
x <- calibrate(x=ewdates$C14Age, errors=ewdates$C14SD, normalised=FALSE)
bins1 <- binPrep(sites=ewdates$SiteID, ages=ewdates$C14Age, h=50)

# Create SpatialPoints
sites <- unique(data.frame(id=ewdates$SiteID,east=ewdates$Eastings,north=ewdates$Northings))
rownames(sites) <- sites$id
sites <- sites[,-1]
sp::coordinates(sites) <- c("east","north")
sp::proj4string(sites) <- sp::CRS("+init=epsg:27700")

#Compute distance matrix
d <- sp::spDists(sites,sites,longlat=FALSE)
#Compute spatial weights 
w <- spweights(d/1000,h=40)
# Define blocks
breaks <- seq(6300,5900,-200) 

# Spatial Permutation Test
res <- sptest(calDates=x,bins=bins1,timeRange=c(6300,5900),locations=sites,permute="locations",nsim=1000,breaks=breaks,spatialweights=w,ncores=1) 
# Plot Results
par(mar=c(1,1,1,1),mfrow=c(1,2))
base=as(ewowin,"SpatialPolygons")
sp::proj4string(base) <- sp::CRS("+init=epsg:27700")
xlim = bbox(base)[1,]
ylim = bbox(base)[2,]
xlim[1] = xlim[1]-100000
plot(base,col="antiquewhite3",border="antiquewhite3",xlim=xlim,ylim=ylim)
plot(res,index=1,option="raw",add=TRUE,legend=TRUE,legSize=0.8,location="topleft",baseSize=0.9)
plot(base,col="antiquewhite3",border="antiquewhite3",xlim=xlim)
plot(res,index=1,option="test",add=TRUE,legend=TRUE,legSize=0.8,location="topleft",baseSize=0.9)
```


# Supplementary Figures

# S1 ... 

# The following figures are not mentioned in the text:


 
## Supplementary Figure 1
The figure below compares an SPD based on  dates calibrated without normalisation (a) to a curve generated by calibrating the sum of gaussian curves based on the CRAs and associated errors. 

```{r}
data(emedyd)
d=subset(emedyd,Region==1&CRA<10000&CRA>7000)

# Create SPD using uncalibrated dates
sumUncalMat=matrix(NA,nrow=length(13000:4000),ncol=nrow(d))
for (i in 1:nrow(d))
{
 sumUncalMat[,i]=dnorm(13000:4000,mean=d$CRA[i],sd=d$Error[i])
}

PrDensNN = apply(sumUncalMat,1,sum)
PrDens = PrDensNN/sum(PrDensNN)
sumUncal=data.frame(CRA=13000:4000,PrDens=PrDens)

# Calibrate the entire uncalibrated SPD 
sumCal=calibrate(as.UncalGrid(sumUncal),eps=0)

# Normalise Probability Sum to Unity
sumCal$PrDens=sumCal$PrDens/sum(sumCal$PrDens)

# Calibrate dates without normalisation
x=calibrate(d$CRA,d$Error,normalised=F)
# Create SPD
SPDnn=spd(x,timeRange=c(12000,8000),spdnormalised=T)
# Plot and Compare
plot(SPDnn)
lines(sumCal$calBP,sumCal$PrDens,col="red",type="l",lwd=1,lty=2)
#legend("bottom",bg="white",legend=c("a","b"),col=c("lightgrey","red"),lwd=c(8,1),lty=c(1,2))
```


## Supplementary Figure 2
```{r}
# Scenario 1: low individual uncertainties. Each date has a time-span of 10 years with a probability of 0.1 for each year.
a=matrix(0,nrow=100,ncol=10)

for (i in 0:9)
{
  a[(1+i*10):((i+1)*10),i+1]=0.1
}

# Scenario 2: high individual uncertainties. Each date has a time-span of 100 years with a probability of 0.01 for each year.
b=matrix(0.01,nrow=100,ncol=10)


#Comparison
par(mfcol=c(2,2))
plot(1:100,apply(a,1,sum),main="SPD dataset a",type="l",ylab="Summed Probability",xlab="time")
plot(1:100,apply(b,1,sum),main="SPD dataset b",type="l",ylab="Summed Probability",xlab="time")

#CKDE based on random dates from each sample, 100 repetitions
set.seed(1)
plot(density(apply(a,2,function(x){sample(1:100,size=1,prob=x)}),bw=10),xlim=c(1,100),ylim=c(0,0.02),col=rgb(0,0,0,0.25),main="CKDE dataset a",xlab="time")
replicate(100,lines(density(apply(datematrix,2,function(x){sample(1:100,size=1,prob=x)}),bw=10),col=rgb(0,0,0,0.2)))
#CKDE based on random dates from each sample, 100 repetitions
plot(density(apply(datematrix2,2,function(x){sample(1:100,size=1,prob=x)}),bw=10),xlim=c(1,100),ylim=c(0,0.025),col=rgb(0,0,0,0.2),main="CKDE dataset b",xlab="time")
replicate(100,lines(density(apply(datematrix2,2,function(x){sample(1:100,size=1,prob=x)}),bw=10),col=rgb(0,0,0,0.2)))
```


## Supplementary Figure 3?

An example of mark permutation test. The simulation envelope represents in this case the panregional model, notice how the width of the simulation envelope is positively correlated to the number of bins in each region.

```{r,fig.height=9,fig.width=4}
# prepare data and generate the panregional spd
data(emedyd)
alldates.emedyd = calibrate(x=emedyd$CRA, errors=emedyd$Error, calCurves='intcal13', normalised=FALSE,verbose=FALSE)
bins = binPrep(sites=emedyd$SiteName, ages=emedyd$CRA, h=50)
alldates.spd = spd(alldates.emedyd,bins=bins,timeRange=c(16000,9000),runm=200,spdnormalised=T,verbose=F)

#execute the permutation test
result = permTest(x=alldates.emedyd, bins=bins, marks=emedyd$Region, timeRange=c(16000,9000), runm=200,nsim=1000,spdnormalised=T,verbose=FALSE)

# plot results
par(mfrow=c(3,1))
plot(result,focalm='1',lwd=2,main=paste0("Southern Levant (n.bins=",result$metadata[[1]][2],")"))
plot(alldates.spd,add=T,type='simple',lty=2,col='grey27')
plot(result,focalm='2',lwd=2,main=paste0("Northern Levant (n.bins=",result$metadata[[2]][2],")"))
plot(alldates.spd,add=T,type='simple',lty=2,col='grey27')
plot(result,focalm='3',lwd=2,main=paste0("South-central Anatolia (n.bins=",result$metadata[[3]][2],")"))
plot(alldates.spd,add=T,type='simple',lty=2,col='grey27')
```


## Supplementary Figure ?1
The script below compares OxCal's SUM function (executed via the _oxcAAR_ package) with rcarbon's `spd()` function. 

```{r}
 ## oxcal via oxcAAR
library(oxcAAR)
quickSetupOxcal()
my_dates <- R_Date(southLevant$LabID, southLevant$CRA, southLevant$Error)
my_sum <- oxcal_Sum(my_dates)
my_result_file <- executeOxcalScript(my_sum)
my_result_text <- readOxcalOutput(my_result_file)
my_result_data <- parseFullOxcalOutput(my_result_text)
res=my_result_data[nrow(southLevant)+3]

n=length(res$`ocd[1]`$likelihood$prob) #number of probabilities
PrDens=res$ocd[[6]][[8]]
resolution=res$ocd[[6]][[7]]
PrDens=PrDens/sum(PrDens)/resolution
calBPs = res$ocd[[6]][[6]]+seq(from=0,by=resolution,length.out=n)-1950

 ## Compute SPD in rcarbon using a wider timeRange to control edge effect
southlevant.spd3 = spd(southlevant.x,verbose=F,timeRange=c(21000,8000))

 ## Compare rcarbon and oxcal
plot(southlevant.spd3,spdnormalised=T,xlim=c(21000,8000),fill.p = 'grey55')
lines(abs(calBPs), PrDens,col="red",lty=1,lwd=1.5)
legend("topleft",legend=c("rcarbon (normalised)","OxCal"),col=c("grey55","red"),lwd=c(15,1.5),lty=c(1,1))
```


## Supplementary Figure ?2

The Bin-sensitivity analysis enables a visual inspection of multiple SPDs generated using different values for the parameter `h` in the binning function (`binPrep()`). High values of `h` will aggregate dates that are futher apart in time. The example below is a subset of Danish dates from the EUROEVOL database, with the binning carried out using median calibrated dates.   

```{r,fig.height=4,fig.width=8}
data(euroevol)
denmark = subset(euroevol,Country=='Denmark'&C14Age<=8000&C14Age>3500)
denmark.x = calibrate(denmark$C14Age,denmark$C14SD,normalised=F,verbose=F)
binsense(x=denmark.x,y=denmark$SiteID,timeRange=c(8000,4000),verbose = F,h=seq(0,200,20),runm=200)
```

## Supplementary Figure ?3


An example of mark permutation test. The simulation envelope represents in this case the panregional model, notice how the width of the simulation envelope is positively correlated to the number of bins in each region.


```{r,fig.height=9,fig.width=4}
# prepare data and generate the panregional spd
data(emedyd)
alldates.emedyd = calibrate(x=emedyd$CRA, errors=emedyd$Error, calCurves='intcal13', normalised=FALSE,verbose=FALSE)
bins = binPrep(sites=emedyd$SiteName, ages=emedyd$CRA, h=50)
alldates.spd = spd(alldates.emedyd,bins=bins,timeRange=c(16000,9000),runm=200,spdnormalised=T,verbose=F)

#execute the permutation test
result = permTest(x=alldates.emedyd, bins=bins, marks=emedyd$Region, timeRange=c(16000,9000), runm=200,nsim=1000,spdnormalised=T,verbose=FALSE)

# plot results
par(mfrow=c(3,1))
plot(result,focalm='1',lwd=2,main=paste0("Southern Levant (n.bins=",result$metadata[[1]][2],")"))
plot(alldates.spd,add=T,type='simple',lty=2,col='grey27')
plot(result,focalm='2',lwd=2,main=paste0("Northern Levant (n.bins=",result$metadata[[2]][2],")"))
plot(alldates.spd,add=T,type='simple',lty=2,col='grey27')
plot(result,focalm='3',lwd=2,main=paste0("South-central Anatolia (n.bins=",result$metadata[[3]][2],")"))
plot(alldates.spd,add=T,type='simple',lty=2,col='grey27')
```


